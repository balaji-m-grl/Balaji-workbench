{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa30b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done!\n",
      "üìÑ Extracted 10 Q&A pairs\n",
      "üìÅ Output folder: D:\\Balaji-workbench\\synthetic data\\output_20260208_220555\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- Patterns for common conversation formats ----------\n",
    "\n",
    "USER_PATTERNS = [\n",
    "    r\"^\\*\\*You:\\*\\*\",\n",
    "    r\"^\\*\\*User:\\*\\*\",\n",
    "    r\"^User:\",\n",
    "    r\"^You:\",\n",
    "    r\"^##\\s*User\",\n",
    "    r\"^##\\s*You\",\n",
    "]\n",
    "\n",
    "ASSISTANT_PATTERNS = [\n",
    "    r\"^\\*\\*ChatGPT:\\*\\*\",\n",
    "    r\"^\\*\\*Assistant:\\*\\*\",\n",
    "    r\"^Assistant:\",\n",
    "    r\"^ChatGPT:\",\n",
    "    r\"^##\\s*Assistant\",\n",
    "    r\"^##\\s*ChatGPT\",\n",
    "]\n",
    "\n",
    "USER_RE = re.compile(\"|\".join(USER_PATTERNS), re.IGNORECASE)\n",
    "ASSISTANT_RE = re.compile(\"|\".join(ASSISTANT_PATTERNS), re.IGNORECASE)\n",
    "\n",
    "# ---------- Core Parsing: split into (user, assistant) ----------\n",
    "\n",
    "def split_conversation(md_text: str) -> List[Tuple[str, str]]:\n",
    "    lines = md_text.splitlines()\n",
    "\n",
    "    blocks = []\n",
    "    current_role = None\n",
    "    current_user = []\n",
    "    current_assistant = []\n",
    "\n",
    "    def flush():\n",
    "        if current_user or current_assistant:\n",
    "            blocks.append((\n",
    "                \"\\n\".join(current_user).strip(),\n",
    "                \"\\n\".join(current_assistant).strip()\n",
    "            ))\n",
    "\n",
    "    for line in lines:\n",
    "        line_stripped = line.strip()\n",
    "\n",
    "        if USER_RE.match(line_stripped):\n",
    "            if current_role is not None:\n",
    "                flush()\n",
    "                current_user = []\n",
    "                current_assistant = []\n",
    "            current_role = \"user\"\n",
    "            continue\n",
    "\n",
    "        if ASSISTANT_RE.match(line_stripped):\n",
    "            current_role = \"assistant\"\n",
    "            continue\n",
    "\n",
    "        if current_role == \"user\":\n",
    "            current_user.append(line)\n",
    "        elif current_role == \"assistant\":\n",
    "            current_assistant.append(line)\n",
    "\n",
    "    flush()\n",
    "    return [(u, a) for u, a in blocks if u.strip() or a.strip()]\n",
    "\n",
    "# ---------- Extract REAL follow-up questions from assistant ----------\n",
    "\n",
    "def extract_suggested_block(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts bullet suggestions after lines like:\n",
    "    'If you want, next I can:'\n",
    "    'Next I can:'\n",
    "    'Suggested:'\n",
    "    \"\"\"\n",
    "    lines = text.splitlines()\n",
    "    collected = []\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if re.search(r\"(if you want|next i can|suggest|follow[- ]?up)\", line, re.IGNORECASE):\n",
    "            j = i + 1\n",
    "            while j < len(lines):\n",
    "                l = lines[j].rstrip()\n",
    "                if l.strip().startswith((\"*\", \"-\", \"‚Ä¢\")):\n",
    "                    collected.append(l.strip())\n",
    "                    j += 1\n",
    "                else:\n",
    "                    break\n",
    "            if collected:\n",
    "                break\n",
    "\n",
    "    return collected\n",
    "\n",
    "# ---------- Writers ----------\n",
    "\n",
    "def write_outputs(pairs: List[Tuple[str, str]], output_dir: Path):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # -------- questions_only.md --------\n",
    "    q_only = output_dir / \"questions_only.md\"\n",
    "    with q_only.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Questions\\n\\n\")\n",
    "\n",
    "        for i, (q, a) in enumerate(pairs, 1):\n",
    "            f.write(f\"## Q{i}\\n\\n\")\n",
    "            f.write(q.strip() + \"\\n\\n\")\n",
    "\n",
    "            suggestions = extract_suggested_block(a)\n",
    "            for j, s in enumerate(suggestions, 1):\n",
    "                clean = re.sub(r\"^[\\-\\*‚Ä¢]\\s*\", \"\", s)\n",
    "                f.write(f\"Q{i}.{j} {clean}\\n\")\n",
    "\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    # -------- Individual Q&A files --------\n",
    "    for i, (q, a) in enumerate(pairs, 1):\n",
    "        out = output_dir / f\"Q{i:03d}.md\"\n",
    "        with out.open(\"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"# Question {i}\\n\\n\")\n",
    "            f.write(\"## User Question\\n\\n\")\n",
    "            f.write(q.strip() + \"\\n\\n\")\n",
    "            f.write(\"## Assistant Answer\\n\\n\")\n",
    "            f.write(a.strip() + \"\\n\")\n",
    "\n",
    "# ---------- Main ----------\n",
    "\n",
    "def main():\n",
    "    path = input(\"Enter path to conversation .md file: \").strip().strip('\"')\n",
    "    file_path = Path(path)\n",
    "\n",
    "    if not file_path.exists():\n",
    "        print(\"‚ùå File not found!\")\n",
    "        return\n",
    "\n",
    "    text = file_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    pairs = split_conversation(text)\n",
    "\n",
    "    if not pairs:\n",
    "        print(\"‚ö†Ô∏è No conversation blocks detected. The format may be unknown.\")\n",
    "        return\n",
    "\n",
    "    base_dir = Path(r\"D:\\Balaji-workbench\\synthetic data\")\n",
    "    run_name = datetime.now().strftime(\"output_%Y%m%d_%H%M%S\")\n",
    "    output_dir = base_dir / run_name\n",
    "\n",
    "    write_outputs(pairs, output_dir)\n",
    "\n",
    "    print(\"‚úÖ Done!\")\n",
    "    print(f\"üìÑ Extracted {len(pairs)} Q&A pairs\")\n",
    "    print(f\"üìÅ Output folder: {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11956d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50469176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done!\n",
      "üìÑ Total questions: 1\n",
      "üß≠ Topology questions: 1\n",
      "üìÅ Output folder: D:\\Balaji-workbench\\synthetic data\\topology_output_20260208_220938\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "# --------- Tune these keywords for \"topology\" meaning ----------\n",
    "TOPOLOGY_KEYWORDS = [\n",
    "    \"topology\", \"connect\", \"connection\", \"connected\", \"flow\", \"communication\",\n",
    "    \"drp\", \"emarker\", \"e-marker\", \"swap\", \"pr_swap\", \"dr_swap\",\n",
    "    \"collision\", \"scenario\", \"cable\", \"device\", \"interoperability\",\n",
    "    \"link\", \"network\", \"path\", \"routing\", \"role\", \"negotiation\"\n",
    "]\n",
    "\n",
    "# ---------- Parse questions-only markdown ----------\n",
    "\n",
    "def extract_questions_only(md_text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts questions from a file formatted like:\n",
    "\n",
    "    ## Q1\n",
    "    question text\n",
    "\n",
    "    ## Q2\n",
    "    question text\n",
    "    \"\"\"\n",
    "    lines = md_text.splitlines()\n",
    "    questions = []\n",
    "    current = []\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(r\"^##\\s*Q\\d+\", line.strip(), re.IGNORECASE):\n",
    "            if current:\n",
    "                questions.append(\"\\n\".join(current).strip())\n",
    "                current = []\n",
    "            continue\n",
    "\n",
    "        # skip separators\n",
    "        if line.strip().startswith(\"---\"):\n",
    "            continue\n",
    "\n",
    "        if line.strip():\n",
    "            current.append(line)\n",
    "\n",
    "    if current:\n",
    "        questions.append(\"\\n\".join(current).strip())\n",
    "\n",
    "    return [q for q in questions if q.strip()]\n",
    "\n",
    "# ---------- Topology filter ----------\n",
    "\n",
    "def is_topology_question(text: str) -> bool:\n",
    "    t = text.lower()\n",
    "    return any(k.lower() in t for k in TOPOLOGY_KEYWORDS)\n",
    "\n",
    "# ---------- Writers ----------\n",
    "\n",
    "def write_outputs(questions: List[str], output_dir: Path):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # -------- topology_questions.md --------\n",
    "    out_md = output_dir / \"topology_questions.md\"\n",
    "    with out_md.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Topology Questions\\n\\n\")\n",
    "        for i, q in enumerate(questions, 1):\n",
    "            f.write(f\"## T{i}\\n\\n\")\n",
    "            f.write(q.strip() + \"\\n\\n\")\n",
    "\n",
    "    # -------- Individual files --------\n",
    "    for i, q in enumerate(questions, 1):\n",
    "        out = output_dir / f\"T{i:03d}.md\"\n",
    "        with out.open(\"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"# Topology Question {i}\\n\\n\")\n",
    "            f.write(q.strip() + \"\\n\")\n",
    "\n",
    "# ---------- Main ----------\n",
    "\n",
    "def main():\n",
    "    path = input(\"Enter path to questions .md file: \").strip().strip('\"')\n",
    "    file_path = Path(path)\n",
    "\n",
    "    if not file_path.exists():\n",
    "        print(\"‚ùå File not found!\")\n",
    "        return\n",
    "\n",
    "    text = file_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    all_questions = extract_questions_only(text)\n",
    "\n",
    "    if not all_questions:\n",
    "        print(\"‚ö†Ô∏è No questions detected. Check the format (## Q1, ## Q2, ...).\")\n",
    "        return\n",
    "\n",
    "    topo_questions = [q for q in all_questions if is_topology_question(q)]\n",
    "\n",
    "    if not topo_questions:\n",
    "        print(\"‚ö†Ô∏è No topology questions matched. Try adjusting TOPOLOGY_KEYWORDS.\")\n",
    "        return\n",
    "\n",
    "    base_dir = Path(r\"D:\\Balaji-workbench\\synthetic data\")\n",
    "    run_name = datetime.now().strftime(\"topology_output_%Y%m%d_%H%M%S\")\n",
    "    output_dir = base_dir / run_name\n",
    "\n",
    "    write_outputs(topo_questions, output_dir)\n",
    "\n",
    "    print(\"‚úÖ Done!\")\n",
    "    print(f\"üìÑ Total questions: {len(all_questions)}\")\n",
    "    print(f\"üß≠ Topology questions: {len(topo_questions)}\")\n",
    "    print(f\"üìÅ Output folder: {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "081975da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No Q&A pairs found. Check your file format.\n",
      "‚úÖ Done!\n",
      "Generated:\n",
      "- C:\\Users\\GRL\\Downloads\\questions_only.md\n",
      "- C:\\Users\\GRL\\Downloads\\qa_files (q1.md, q2.md, ...)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Ask user for input file path\n",
    "input_path = input(\"Enter path to conversation.md: \").strip().strip('\"').strip(\"'\")\n",
    "\n",
    "\n",
    "input_file = Path(input_path)\n",
    "\n",
    "if not input_file.exists():\n",
    "    print(\"‚ùå File not found:\", input_file)\n",
    "    exit(1)\n",
    "\n",
    "text = input_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# Split by User blocks\n",
    "blocks = re.split(r\"## User:\\s*\", text)\n",
    "blocks = [b.strip() for b in blocks if b.strip()]\n",
    "\n",
    "qa_pairs = []\n",
    "\n",
    "for block in blocks:\n",
    "    parts = re.split(r\"## Assistant:\\s*\", block)\n",
    "    if len(parts) != 2:\n",
    "        continue\n",
    "\n",
    "    user_q = parts[0].strip()\n",
    "    assistant_text = parts[1].strip()\n",
    "\n",
    "    # Extract suggested questions (lines starting with \"- \")\n",
    "    suggested = re.findall(r\"- (.+)\", assistant_text)\n",
    "\n",
    "    # Remove suggested section from answer (simple cleanup)\n",
    "    answer = re.sub(r\"\\*\\*Suggested questions:\\*\\*[\\s\\S]*\", \"\", assistant_text).strip()\n",
    "\n",
    "    qa_pairs.append({\n",
    "        \"question\": user_q,\n",
    "        \"answer\": answer,\n",
    "        \"suggested\": suggested\n",
    "    })\n",
    "\n",
    "if not qa_pairs:\n",
    "    print(\"‚ö†Ô∏è No Q&A pairs found. Check your file format.\")\n",
    "    exit(1)\n",
    "\n",
    "# Output files in same directory as input\n",
    "output_dir = input_file.parent\n",
    "\n",
    "# 1) Write questions_only.md\n",
    "q_only_lines = [\"# Questions\\n\"]\n",
    "for qa in qa_pairs:\n",
    "    q_only_lines.append(f\"- {qa['question']}\")\n",
    "    for s in qa[\"suggested\"]:\n",
    "        q_only_lines.append(f\"  - Suggested: {s}\")\n",
    "    q_only_lines.append(\"\")\n",
    "\n",
    "(output_dir / \"questions_only.md\").write_text(\"\\n\".join(q_only_lines), encoding=\"utf-8\")\n",
    "\n",
    "# 2) Write many files: one Q&A per file\n",
    "qa_dir = output_dir / \"qa_files\"\n",
    "qa_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for i, qa in enumerate(qa_pairs, start=1):\n",
    "    content = (\n",
    "        f\"# Question\\n{qa['question']}\\n\\n\"\n",
    "        f\"# Answer\\n{qa['answer']}\\n\"\n",
    "    )\n",
    "    (qa_dir / f\"q{i}.md\").write_text(content, encoding=\"utf-8\")\n",
    "\n",
    "print(\"‚úÖ Done!\")\n",
    "print(\"Generated:\")\n",
    "print(\"-\", output_dir / \"questions_only.md\")\n",
    "print(\"-\", qa_dir, \"(q1.md, q2.md, ...)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536bc8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done!\n",
      "üìÑ Processed 9 Q&A pairs\n",
      "üìÅ Output folder: D:\\Balaji-workbench\\synthetic data\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ---------- Patterns for common conversation formats ----------\n",
    "\n",
    "USER_PATTERNS = [\n",
    "    r\"^\\*\\*You:\\*\\*\",\n",
    "    r\"^\\*\\*User:\\*\\*\",\n",
    "    r\"^User:\",\n",
    "    r\"^You:\",\n",
    "    r\"^##\\s*User\",\n",
    "    r\"^##\\s*You\",\n",
    "]\n",
    "\n",
    "ASSISTANT_PATTERNS = [\n",
    "    r\"^\\*\\*ChatGPT:\\*\\*\",\n",
    "    r\"^\\*\\*Assistant:\\*\\*\",\n",
    "    r\"^Assistant:\",\n",
    "    r\"^ChatGPT:\",\n",
    "    r\"^##\\s*Assistant\",\n",
    "    r\"^##\\s*ChatGPT\",\n",
    "]\n",
    "\n",
    "USER_RE = re.compile(\"|\".join(USER_PATTERNS), re.IGNORECASE)\n",
    "ASSISTANT_RE = re.compile(\"|\".join(ASSISTANT_PATTERNS), re.IGNORECASE)\n",
    "\n",
    "# ---------- Conversation Splitter ----------\n",
    "\n",
    "def split_conversation(md_text: str) -> List[Tuple[str, str]]:\n",
    "    lines = md_text.splitlines()\n",
    "\n",
    "    blocks = []\n",
    "    current_role = None\n",
    "    current_user = []\n",
    "    current_assistant = []\n",
    "\n",
    "    def flush():\n",
    "        if current_user or current_assistant:\n",
    "            blocks.append((\n",
    "                \"\\n\".join(current_user).strip(),\n",
    "                \"\\n\".join(current_assistant).strip()\n",
    "            ))\n",
    "\n",
    "    for line in lines:\n",
    "        line_stripped = line.strip()\n",
    "\n",
    "        if USER_RE.match(line_stripped):\n",
    "            if current_role == \"assistant\":\n",
    "                flush()\n",
    "                current_user = []\n",
    "                current_assistant = []\n",
    "            current_role = \"user\"\n",
    "            continue\n",
    "\n",
    "        if ASSISTANT_RE.match(line_stripped):\n",
    "            current_role = \"assistant\"\n",
    "            continue\n",
    "\n",
    "        if current_role == \"user\":\n",
    "            current_user.append(line)\n",
    "        elif current_role == \"assistant\":\n",
    "            current_assistant.append(line)\n",
    "\n",
    "    flush()\n",
    "    return [(u, a) for u, a in blocks if u.strip() or a.strip()]\n",
    "\n",
    "# ---------- Precise Suggested Question Extraction ----------\n",
    "\n",
    "SECTION_TRIGGERS = [\n",
    "    \"suggested questions\",\n",
    "    \"follow-up questions\",\n",
    "    \"follow up questions\",\n",
    "    \"next questions\",\n",
    "    \"you can ask\",\n",
    "    \"you might ask\",\n",
    "    \"consider asking\",\n",
    "    \"if you want next\",\n",
    "]\n",
    "\n",
    "def extract_suggested_questions(answer_text: str) -> List[str]:\n",
    "    suggestions = []\n",
    "    seen = set()\n",
    "\n",
    "    lines = [l.strip() for l in answer_text.splitlines() if l.strip()]\n",
    "\n",
    "    capture_mode = False\n",
    "\n",
    "    # Verbs that often indicate \"offer-style\" suggestions\n",
    "    OFFER_VERBS = (\n",
    "        \"show\", \"help\", \"design\", \"draft\", \"map\", \"explain\", \"build\",\n",
    "        \"create\", \"generate\", \"analyze\", \"analyse\", \"walk\", \"outline\"\n",
    "    )\n",
    "\n",
    "    for line in lines:\n",
    "        low = line.lower()\n",
    "\n",
    "        # Detect section headers like \"If you want next, I can:\"\n",
    "        if any(t in low for t in SECTION_TRIGGERS) or low.endswith(\"i can:\") or low.endswith(\"i can\"):\n",
    "            capture_mode = True\n",
    "            continue\n",
    "\n",
    "        # Bullet or numbered list items\n",
    "        is_list_item = bool(\n",
    "            re.match(r\"^[-*‚Ä¢]\\s+\", line) or re.match(r\"^\\d+[\\.\\)]\\s+\", line)\n",
    "        )\n",
    "\n",
    "        if is_list_item:\n",
    "            clean = re.sub(r\"^([-*‚Ä¢]|\\d+[\\.\\)])\\s*\", \"\", line).strip()\n",
    "            if len(clean) > 5:\n",
    "                # Case 1: already a real question\n",
    "                if \"?\" in clean:\n",
    "                    q = clean if clean.endswith(\"?\") else clean + \"?\"\n",
    "                else:\n",
    "                    # Case 2: offer-style suggestion ‚Üí convert to question\n",
    "                    first_word = clean.split()[0].lower()\n",
    "                    if first_word in OFFER_VERBS:\n",
    "                        # \"Show X\" -> \"Can you show X?\"\n",
    "                        q = \"Can you \" + clean[0].lower() + clean[1:]\n",
    "                        if not q.endswith(\"?\"):\n",
    "                            q += \"?\"\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                key = q.lower()\n",
    "                if key not in seen:\n",
    "                    seen.add(key)\n",
    "                    suggestions.append(q)\n",
    "            continue\n",
    "\n",
    "        # If we are in a \"suggestions\" section, also capture plain question sentences\n",
    "        if capture_mode:\n",
    "            if line.endswith(\"?\"):\n",
    "                key = line.lower()\n",
    "                if key not in seen:\n",
    "                    seen.add(key)\n",
    "                    suggestions.append(line)\n",
    "            else:\n",
    "                # stop when normal paragraph resumes\n",
    "                capture_mode = False\n",
    "\n",
    "    return suggestions\n",
    "\n",
    "# ---------- Writers ----------\n",
    "\n",
    "def write_outputs(pairs: List[Tuple[str, str]], output_dir: Path):\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # questions_only.md\n",
    "    q_only = output_dir / \"questions_only.md\"\n",
    "    with q_only.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Suggested / Follow-up Questions Only\\n\\n\")\n",
    "\n",
    "        for i, (q, a) in enumerate(pairs, 1):\n",
    "            suggestions = extract_suggested_questions(a)\n",
    "\n",
    "            if not suggestions:\n",
    "                continue\n",
    "\n",
    "            f.write(f\"## Q{i}\\n\\n\")\n",
    "            f.write(q.strip() + \"\\n\\n\")\n",
    "\n",
    "            for j, s in enumerate(suggestions, 1):\n",
    "                f.write(f\"- Q{i}.{j} {s}\\n\")\n",
    "\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    # Individual QA files\n",
    "    for i, (q, a) in enumerate(pairs, 1):\n",
    "        out = output_dir / f\"Q{i:03d}.md\"\n",
    "        with out.open(\"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"# Question {i}\\n\\n\")\n",
    "            f.write(\"## User Question\\n\\n\")\n",
    "            f.write(q.strip() + \"\\n\\n\")\n",
    "            f.write(\"## Assistant Answer\\n\\n\")\n",
    "            f.write(a.strip() + \"\\n\\n\")\n",
    "\n",
    "            suggestions = extract_suggested_questions(a)\n",
    "            if suggestions:\n",
    "                f.write(\"## Suggested / Follow-up Questions\\n\\n\")\n",
    "                for j, s in enumerate(suggestions, 1):\n",
    "                    f.write(f\"- Q{i}.{j} {s}\\n\")\n",
    "\n",
    "# ---------- Main ----------\n",
    "\n",
    "def main():\n",
    "    path = input(\"Enter path to conversation .md file: \").strip().strip('\"')\n",
    "    file_path = Path(path)\n",
    "\n",
    "    if not file_path.exists():\n",
    "        print(\"‚ùå File not found!\")\n",
    "        return\n",
    "\n",
    "    text = file_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    pairs = split_conversation(text)\n",
    "\n",
    "    if not pairs:\n",
    "        print(\"‚ö†Ô∏è No conversation blocks detected. The format may be unknown.\")\n",
    "        return\n",
    "\n",
    "    output_dir = Path(r\"D:\\Balaji-workbench\\synthetic data\")\n",
    "\n",
    "    write_outputs(pairs, output_dir)\n",
    "\n",
    "    print(\"‚úÖ Done!\")\n",
    "    print(f\"üìÑ Processed {len(pairs)} Q&A pairs\")\n",
    "    print(f\"üìÅ Output folder: {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ac04d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done!\n",
      "üìÑ Processed 9 Q&A pairs\n",
      "üìÅ Output folder: D:\\Balaji-workbench\\synthetic data\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ---------- Patterns for common conversation formats ----------\n",
    "\n",
    "USER_PATTERNS = [\n",
    "    r\"^\\*\\*You:\\*\\*\",\n",
    "    r\"^\\*\\*User:\\*\\*\",\n",
    "    r\"^User:\",\n",
    "    r\"^You:\",\n",
    "    r\"^##\\s*User\",\n",
    "    r\"^##\\s*You\",\n",
    "]\n",
    "\n",
    "ASSISTANT_PATTERNS = [\n",
    "    r\"^\\*\\*ChatGPT:\\*\\*\",\n",
    "    r\"^\\*\\*Assistant:\\*\\*\",\n",
    "    r\"^Assistant:\",\n",
    "    r\"^ChatGPT:\",\n",
    "    r\"^##\\s*Assistant\",\n",
    "    r\"^##\\s*ChatGPT\",\n",
    "]\n",
    "\n",
    "USER_RE = re.compile(\"|\".join(USER_PATTERNS), re.IGNORECASE)\n",
    "ASSISTANT_RE = re.compile(\"|\".join(ASSISTANT_PATTERNS), re.IGNORECASE)\n",
    "\n",
    "# ---------- Conversation Splitter ----------\n",
    "\n",
    "def split_conversation(md_text: str) -> List[Tuple[str, str]]:\n",
    "    lines = md_text.splitlines()\n",
    "\n",
    "    blocks = []\n",
    "    current_role = None\n",
    "    current_user = []\n",
    "    current_assistant = []\n",
    "\n",
    "    def flush():\n",
    "        if current_user or current_assistant:\n",
    "            blocks.append((\n",
    "                \"\\n\".join(current_user).strip(),\n",
    "                \"\\n\".join(current_assistant).strip()\n",
    "            ))\n",
    "\n",
    "    for line in lines:\n",
    "        line_stripped = line.strip()\n",
    "\n",
    "        if USER_RE.match(line_stripped):\n",
    "            if current_role == \"assistant\":\n",
    "                flush()\n",
    "                current_user = []\n",
    "                current_assistant = []\n",
    "            current_role = \"user\"\n",
    "            continue\n",
    "\n",
    "        if ASSISTANT_RE.match(line_stripped):\n",
    "            current_role = \"assistant\"\n",
    "            continue\n",
    "\n",
    "        if current_role == \"user\":\n",
    "            current_user.append(line)\n",
    "        elif current_role == \"assistant\":\n",
    "            current_assistant.append(line)\n",
    "\n",
    "    flush()\n",
    "    return [(u, a) for u, a in blocks if u.strip() or a.strip()]\n",
    "\n",
    "# ---------- Suggested Question Extraction ----------\n",
    "\n",
    "SECTION_TRIGGERS = [\n",
    "    \"suggested questions\",\n",
    "    \"follow-up questions\",\n",
    "    \"follow up questions\",\n",
    "    \"next questions\",\n",
    "    \"you can ask\",\n",
    "    \"you might ask\",\n",
    "    \"consider asking\",\n",
    "    \"if you want next\",\n",
    "    \"i can:\",\n",
    "]\n",
    "\n",
    "def strip_markdown(text: str) -> str:\n",
    "    # Remove **bold**, *italic*, __underline__, etc.\n",
    "    text = re.sub(r\"(\\*\\*|\\*|__|_)\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_suggested_questions(answer_text: str) -> List[str]:\n",
    "    suggestions = []\n",
    "    seen = set()\n",
    "\n",
    "    lines = [l.rstrip() for l in answer_text.splitlines() if l.strip()]\n",
    "\n",
    "    capture_mode = False\n",
    "\n",
    "    for line in lines:\n",
    "        low = line.lower().strip()\n",
    "\n",
    "        # Detect section headers like \"If you want next, I can:\"\n",
    "        if any(t in low for t in SECTION_TRIGGERS):\n",
    "            capture_mode = True\n",
    "            continue\n",
    "\n",
    "        # Bullet or numbered list items\n",
    "        is_list_item = bool(\n",
    "            re.match(r\"^\\s*[-*‚Ä¢]\\s+\", line) or re.match(r\"^\\s*\\d+[\\.\\)]\\s+\", line)\n",
    "        )\n",
    "\n",
    "        if capture_mode and is_list_item:\n",
    "            clean = re.sub(r\"^\\s*([-*‚Ä¢]|\\d+[\\.\\)])\\s*\", \"\", line).strip()\n",
    "            clean = strip_markdown(clean)\n",
    "\n",
    "            # Remove leading \"or \"\n",
    "            if clean.lower().startswith(\"or \"):\n",
    "                clean = clean[3:].strip()\n",
    "\n",
    "            if len(clean) > 5:\n",
    "                # Turn into a question\n",
    "                # Make first letter lowercase after \"Can you\"\n",
    "                q_body = clean[0].lower() + clean[1:]\n",
    "                q = \"Can you \" + q_body\n",
    "                if not q.endswith(\"?\"):\n",
    "                    q += \"?\"\n",
    "\n",
    "                key = q.lower()\n",
    "                if key not in seen:\n",
    "                    seen.add(key)\n",
    "                    suggestions.append(q)\n",
    "            continue\n",
    "\n",
    "        # If we leave the bullet list, stop capture mode\n",
    "        if capture_mode and not is_list_item:\n",
    "            capture_mode = False\n",
    "\n",
    "    return suggestions\n",
    "\n",
    "# ---------- Writers ----------\n",
    "\n",
    "def write_outputs(pairs: List[Tuple[str, str]], output_dir: Path):\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # questions_only.md\n",
    "    q_only = output_dir / \"questions_only.md\"\n",
    "    with q_only.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Suggested / Follow-up Questions Only\\n\\n\")\n",
    "\n",
    "        for i, (q, a) in enumerate(pairs, 1):\n",
    "            suggestions = extract_suggested_questions(a)\n",
    "\n",
    "            if not suggestions:\n",
    "                continue\n",
    "\n",
    "            f.write(f\"## Q{i}\\n\\n\")\n",
    "            f.write(q.strip() + \"\\n\\n\")\n",
    "\n",
    "            for j, s in enumerate(suggestions, 1):\n",
    "                f.write(f\"- Q{i}.{j} {s}\\n\")\n",
    "\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    # Individual QA files\n",
    "    for i, (q, a) in enumerate(pairs, 1):\n",
    "        out = output_dir / f\"Q{i:03d}.md\"\n",
    "        with out.open(\"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"# Question {i}\\n\\n\")\n",
    "            f.write(\"## User Question\\n\\n\")\n",
    "            f.write(q.strip() + \"\\n\\n\")\n",
    "            f.write(\"## Assistant Answer\\n\\n\")\n",
    "            f.write(a.strip() + \"\\n\\n\")\n",
    "\n",
    "            suggestions = extract_suggested_questions(a)\n",
    "            if suggestions:\n",
    "                f.write(\"## Suggested / Follow-up Questions\\n\\n\")\n",
    "                for j, s in enumerate(suggestions, 1):\n",
    "                    f.write(f\"- Q{i}.{j} {s}\\n\")\n",
    "\n",
    "# ---------- Main ----------\n",
    "\n",
    "def main():\n",
    "    path = input(\"Enter path to conversation .md file: \").strip().strip('\"')\n",
    "    file_path = Path(path)\n",
    "\n",
    "    if not file_path.exists():\n",
    "        print(\"‚ùå File not found!\")\n",
    "        return\n",
    "\n",
    "    text = file_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    pairs = split_conversation(text)\n",
    "\n",
    "    if not pairs:\n",
    "        print(\"‚ö†Ô∏è No conversation blocks detected. The format may be unknown.\")\n",
    "        return\n",
    "\n",
    "    output_dir = Path(r\"D:\\Balaji-workbench\\synthetic data\")\n",
    "\n",
    "    write_outputs(pairs, output_dir)\n",
    "\n",
    "    print(\"‚úÖ Done!\")\n",
    "    print(f\"üìÑ Processed {len(pairs)} Q&A pairs\")\n",
    "    print(f\"üìÅ Output folder: {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
